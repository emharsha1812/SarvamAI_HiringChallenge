 Congratulations to you Mr. Raghavan for that. Thank you so much for joining us. Over to you. Hi everybody, how are you? Okay, I am not hearing this at all. It's like a post-lunch energy downer or something. Let's hear it. Are you guys awake? All right, you better be because we have a superstar guest here. You heard the 41 million dollars and I didn't hear honestly anything she said after that. So we're going to ask for about 40 million dollars from him by the end of this conversation. Okay, but let's get started. I want to introduce Vivek and Pratyush, his co-founder who's not here. We wanted to start with playing a video of what OpenHati does. I encourage all of you to go to the website, several of them, and check it out. But let me start by introducing Vivek. Vivek is a dear friend and he's very, very modest. He's one of the most modest guys that I know. But his personal journey, Vivek, you've been, you got a PhD from Kaniyamalyn. You sat and sold a company to Magma. And Vivek and I moved back to India from, we were both in the valley on the same day actually. And you've been in India for the last 16 years. And what most people don't know is your journey at Aadhar. He spent 13 years selflessly at Aadhar. Nobody would have heard of him, but he was a pioneering technology visionary behind Aadhar, which we all take for granted today. So please give it out. So honestly, when people, when I think of selfless service, truly selfless service, I always think of Vivek. And since then, he also was at AI for Bharat, which we're going to touch on, where he met Pratyush's other co-founder. Pratyush had a PhD from ETH at Zurich. He was in IBM research. He was at Microsoft research playing a key role and a faculty at IIT Madras and at AI for Bharat. So that's a little brief introduction about them. These guys are modest, modest engineers. So they don't toot their own horn. So forgive me for tooting their horn in this case. But let's jump right in about the money. Funding. $41 million, man. That's a lot of money, right? Every entrepreneur here is saying, what the hell did guys, these guys do? What did the investors see to write such a big check? No, I think it's a trend of what, the new trend of what's going on in India. I think that for the very first time, I think the investors have looked at, let's try and build something deep deck out of the country and let's try to figure out how to build something as a foundational technology out of the country. That's really what's really exciting. And I think that about, as Bala was mentioning for the last 15 years, I've been working in both digital public infrastructure and non-profit things. But when this whole thing of generative AI came about, we said, okay, how can I actually make a difference in this space? And I said, maybe this is the opportunity to actually come out and really build something. And the only way that we realize that you can do it is actually in the private sector. And I think that's that. And then we went out there and we said, we want to build something which is a continuation, right? And fundamentally, the question is, the reason of what we want to do at ServaM AI is we want to basically make generative AI available and accessible to the people in the country. And that's the intent. And when we said that we want to do this, there was a resonance in the investment community. And I think it's a responsibility to really to show that something like this can be built out of India. So we see that as confidence and a responsibility. And I also hope it's a trend that there are many more people like us who are backed because if you look at it, maybe it's a large number in the Indian context, but in the global context, I think there should be many, many more entrepreneurs who are back to do things in India. I'm going to come back to the many more entrepreneurs. Obviously, I'm going to ask you about Bhavish's Khrutram. So we're going to come back to that question. But again, $41 million. All of what you said, $2 million, that's a good amount of money for a startup which is not yet built anything. What are you going to do with all this money? I can have a perfect solution for the problem. I think in the last week, I've got lots of calls of lots of people telling me how I can do. I know you first, okay? I'll be landed in the same day. I'm in front of the queue. But honestly, I think the key thing in this is to putting together an amazing team. And we actually have an amazing team, but we believe that it is talent that will drive this kind of thing. And so it is to get key talent. And of course, the other thing is compute. This is extremely expensive compute-wise to actually do these kinds of things. And I think that those are the two primary things that would use this for. Okay. I'm computing in my own head as an entrepreneur. Talent, okay, you have like 20, 15 people. How much are you paying these guys? But okay, well, you won't touch on that. But let's talk about what you guys actually built. What is OpenHati? How would you explain OpenHati to many people here who might not have known about it? So I think OpenHati is, so first of all, right? We come from, I personally come from the open source ecosystem and we, and also from the DPI ecosystem. So we believe that for this to work, we need the ecosystem to be successful. And as a result of that, one of the first things we did was, hey, there are these open source large language models that exist, right? I mean, everybody knows about the Lama family from Meta. They also, there are others like Mistral. There are a bunch of open source, you know, large language models. And then we said, is there any way that take an existing open source model and teach it language skills, right? I mean, and that is really the, you know, what we decide, what we said that can we do something like that? And is this a, you know, relatively frugal way of, of actually, you know, making models, you know, work in, in, in diverse languages? Because the truth is still today. I mean, if you look at the amount of data and knowledge, it is still English dominates these things. And, and, and I think that how do you actually take and make it understand Indian language, understand Indian context and all of those things in, in actually a, in an efficient way? And therefore this was an attempt through that. And, and it's a, Open Hathi is, you know, is, is currently based on the Lama seven billion model, but we'll be releasing many more models in different languages, different sizes, and things like that as part of this, as part of this series. And, and of course, you know, we will be building further models on those and doing other things to, to, to actually, and we'll also have endpoints that people can use. So the, it's not, it's definitely, you know, something that people can, can, can use to things. And the, that's, that's the essence of, of what, what this Open Hathi is. So what does it mean to people in the audience here who are either doing their own startups or a business or, or developers? How should they look at Open AI? Sorry, sorry. No, yeah, no, no, I think, I think the way you look at it is that we, we are one of the important things that we are doing is we're not just building models. We are also going to be building a, a platform, a platform for developers where you can actually use a combination of various different kinds of models, some which are from us, some which are open source, some which may not be open source and actually to actually pull together and figure out how to deploy, you know, generative AI applications at scale and understand and evaluate their performance in an efficient manner. And that's something that we are planning to do at this, and this platform is, you know, in the next couple of months will be coming out there. It will be available to developers. But of course, those who want to start with the open source things and hack for that, of course, please go ahead and do that as well. That's, that is phenomenal. But how does it compare to Open AI itself or Google? See, at least the things that we are doing now, right? I mean, one of the things that when we thought about building Sarvam, we said we want to build a full stack generative AI company and different people have, and our understanding of full stack is that we need to know how to train models from scratch. We need to know how to kind of figure out how to deploy models to solve real world use cases. And we need to play in the ecosystem to make sure that we can actually deploy population scale applications, right? So we were thinking about all of these things. But still the models we were talking about are, you know, fairly small models. They are fairly small models, right? The 7 to maybe up to 70 billion kind of range we're talking about. While these models like Open AI and Google are obviously much bigger models, right? But we want to, but, you know, we want to understand the techniques and be able to build that muscle to do all of these things to make it available to people. Now those models are, I mean, as I said, you know, I think that there is space for all of those things. And I think as even Sridhar was talking about earlier in the day, we believe that these smaller models can do very, I mean, many, many kind of domain specific tasks extremely well, probably even better than the larger models. And that is really one of the key areas. And so the further value of these kinds of things, right? We're not aiming in these most set of models to build any AGI, right? That's not our goal here. Our goal is to make things that work extremely well for domain specific use cases or increase accessibility through language and all of those kinds of things. And obviously all of this unique to India. But what is unique about India? I mean, like, what is, is there anything special in our ecosystem that makes small models focused with Indian languages better for, more suited for our problems? So I think that, I mean, there are quite a few things that are unique about India, right? The first thing is, I think that we are a voice first nation. So therefore, I think voice has to be the core to doing things. The other thing, of course, India is extremely, it's a cost-conscious country from a cost perspective. Now, I would say that there are lots of interesting use cases where you can use open AI and the cost structure works that when, depending on your application. But when you want to scale things to a massive level and make it work, then, then you have to figure out how small models work. So that's something that is also specific to India. The third thing which is specific to India is really the success that India has had in building all this digital public infrastructure. When you add the AI layer on top of it, then you can actually get dramatic, you know, dramatic, I think, multiplicative combinatorial effects based on doing things like that. That's a phenomenal point. Like, you know, it's like DPI to the power of AI almost in some ways. And as a part of Adar, building Adar, no better person than you. So in summary, what I'm hearing is small models specialized with trained with index specific language data suited for Indian problems at a compelling cost point will be suited for us. We're not solving some world autonomous vehicles or some complex problem. We're solving some basic problems specifically focused with on voice with multiple languages. That is what you see as the future. Am I paraphrasing this correctly? No, yeah. So I think that certainly, I mean, voice and Indian languages are an important part of our strategy, but we will be building, you know, custom models to solve various other kinds of problems as well. Right? That's not just limited to, I think, in different domains, working data that enterprises have and things like that. So that's something that we'll also look at. Fair enough. So coming back to the elephant in the room, no, no pun intended with open Hathi. What about Bhavishakirwal and Kruthrim? What is your take on that? I think it's great. I think it's absolutely, it's wonderful, right? I mean, the fact that the technology AI is so important that we need multiple people working on it. The fact that there are other people thinking is actually validates that this is an important problem to be solved. And I think that, and we need everybody to come together and do that. So I really welcome that. I think it's great. And I think that there'll be different people who will have different takes as to how to solve this kind of problem. And hopefully as a result of that, the entire ecosystem benefits. One more question. And then I want to talk about some of the predictions that you've boldly made. So Vivek, I usually ask people about what do you think the future will be and everybody usually hedges. I asked Vivek, what do you think is going to happen by December 2024? What do you think sitting in this room one year later we can expect? And he made three bold predictions. So I want to talk about that before that. I have one last question. What are the top three applications that you think are relevant for India? You had three that talked about medical. When we quick summary, what do you think the top three apps are for India, for AI? So I mean, I think that as you said, things like education and medical are clearly areas where I think that things can be leveraged. The whole idea of all these kind of the DPI aspect of it is another major application where things can happen. And here I'm talking about country specific work. And I think the whole idea which Rheeter also talked about was the concept of software. And I think that and clearly we have a very large software industry and how to reimagine those things in this context is also something that's going to be. Fair enough. Are you guys ready for Vivek Raghavan's bold predictions? Yes? No, I'm not hearing any yes yet. This is like a big deal. He's like one of the smartest guys that I know. He wants to make three predictions. You don't want to hear it. All right. So I asked him, what do you think, you know, year later, what do you think we can expect? And he came up with three things and usually people give very blunt answers when you ask a question like this because they don't want to be caught wrong. Not Vivek. Vivek is bold. So he basically said three things and I'm going to list out the three things and then he's asking about it. So number one, he says, I will prefer to talk to an automated customer service than a real person because they'll give me a better answer. So that is Vivek Raghavan's prediction number one. So number two is that when everybody is talking about a GPU shortage, Vivek predicts that there'll be a GPU glut in India. He thinks there'll be too much GPU. Okay. So if you want to short and media stock, this is a good time. And number three, which was extremely unexpected, he said some companies will suddenly die. Okay. So Vivek, these are not what I expected. So do you want to quickly talk about each of them? Why you just came up with these and then we'll throw the audience questions. So I don't think I quite said it the way that I'm thinking. But it's interesting. But I think the first thing that we said is I think that and I don't think that this is, I think there will come a time when, you know, in areas of customer service, et cetera, when you want to do something very specific, today, you know, when you call, when you call some kind of a bot, you actually end up, you mostly try to disconnect the call or, you know, you're extremely upset that you're talking to a bot. But I think that there will come a time and I'm predicting it is sooner than later that you will actually get better responses from the bot than what the human representative, at least the average human representative that you could talk to could give. And I think that that's just a, I just said that there will come a time where you know it's not a human you're talking to, but it's probably more likely to solve your intent than the human person. That's just something that I think that could happen. Okay. Definitely controversial. But we'll let it go. What about the GPU glut? No, no, yeah. So I don't think that, so I think that the fact that there is a tremendous shortage right now, I think that shortage will ease because that is how the cycles of things go, right? When, when, you know, I think the fact that there was such a severe shortage last year, you know, basically caused a number of different players to ramp up in various kinds of forms. And I think that that, that, that will always go in a cycle. But you may, we may find out that there are many, many more interesting problems that people will be able to solve. I'm, I still remember, you know, we were at, at, at a, at a Gen AI event in, in Bangalore and we were talking to people and we said, you know, how many people have access to, you know, a four A hundreds? This was the question that I'd asked and nobody in the room. And these are all extremely enthusiastic Gen AI people and nobody had access. And I think that thing is going to change. You will be able to get these kinds of things and people who want to hack and do things will have access to these things at, in, in without, you know, having to write a, you know, a major check, check. Vivek is also a semiconductor guy before he went into other. So I would take his predictions very seriously. So I don't know what I, I'm going to sell my in media stock. I would not do that. But that's not what I said. I want to blame you for this. It goes up. But the third one is pretty strange. You know, companies are born, companies die, but you said some companies will suddenly die. What does that mean? No, I think, see, I think the, the interesting thing is, and I think that if it comes back to the fundamental nature of AI, AI is a tool, right? And you have to use that and you have to use that within your business process, right? And how AI is being used. And so, and what's going to happen is that, I mean, I think this is true with, with, you know, when someone said in terms of, you know, people, they said that the people who leverage AI will be, will, will be more effective than those who don't leverage AI. And that will still for organizations also. Organizations that leverage AI in fundamentally in their core business processes will be more effective than those who don't, right? And I think that's the thing. And you won't know the difference until one day it becomes too obvious and it will be too late. And I think that's the reason why everybody needs to think about what it means for your business, because you will, everything will be fine. Everything will be fine. Then one day somebody in your, either, either your competitor in your space or somebody brand new coming into your space will be reimagining your business process completely. And at that stage you will find that it's, you know, it's a, it's a very big, very tall, you know, mountain to climb. And that's why I think it's important for both people and entities to think about how they will, you know, they, they will upgrade themselves or they will modify their business processes to, you know, to. That's a very nuanced answer. And everybody, everybody here who's running a business should really think about it because life will be the same. And then suddenly, suddenly something will, you know, then there will be a step change. We make, I have a few more questions, but I'm sure the audience has a lot of questions for you. So how are we doing on time? Okay. So does, okay, a lot of questions. So love to, is there a mic that we can pass around? Thank you. My name is Karthik. I work for IT service industry. So you're saying that you're working on LLM, sorry, it's a fine tuned LLM on top of Lama. My basic question, fundamental question is we don't have a fundamental, foundational model for India. Most of the models are basically using English or those kind of things. For example, even Andrew was talking about the tokenizers and things like that. So are you working on anything like that? Or you, do you want to use mostly the existing models and run on top of it? Or you're going to. You asked a good question. You asked a cherry question for himself. No, I think the, the, the interesting thing is that if you look at, and then we have actually a blog on this, on our website, I think one of the things that we've actually built a, a customized tokenizer, which actually fundamentally changes the cost of some of these generations in Indian languages. And, and I think that we are, we're not just fine tuning. We're actually, we are leveraging the existing pre training, but we are doing what's known as continual free training, which actually, but having said that, you know, I think that when we have to figure out where is the data to train an extremely large model from scratch. And some of those things are things which will happen over time. But I think that, I think that, yes, I think that we will be doing various kinds of things. But the interesting thing is that if I want to change the accessibility problem with an existing open source model, how do I do that? And that's the problem that we have, that we think we have solved and, and, and is going to be the heart of this open heart series. Extremely well explained in the blog even I could understand it. So Hi, I'm Prishant. I work for a fintech company. My question is like, unlike China, we never had a consumer facing application coming out from India and in web one, web two, crypto and all. Why do you think it will be different this time in like AI? Because will the DPI and other things will serve the same purpose, but the great firewall did in China? Or do you think like in because AI is a strategic sector, no outside country can work in NASA projects. Maybe our government contract will go to them. What are the, at least the moat here for an Indian company? So I don't, I think, I think the question is, I don't know the answer to these questions, right? I mean, I, I, and I think that it's difficult to predict, but I do believe and as I'm repeating that the combinatorial effect of being using gen AI at a large scale in addition in along with the DPI work that we've done in India will have people. And I, and I think that in the end, it is the, the intent is that people need to be able to use it and they will vote by things that are useful for them. And if that doesn't happen, you're right that, that, and I think that we have to figure out what is the mechanism of delivery of apps, right? I mean, in, in, how, where do Indians consume content? That's the question. I'm so sorry, but we are out of time. Vivek will be outside. So he would be able to answer the question. Do we have time for one last question? Can I, can I just take one last? Yeah. Thank you. Thank you. I'm Manish Kothari. I'm from ISBR Business School. Good that I got a chance to ask you this question. During lunchtime, there were a few of our educationists whom we were talking about and we were, there was one from school and we are from the MBA institutions. We were thinking of these present generations. How do we get them into what you are doing? There is one thing that they have been regularly, that the concentrations that they're working on, but artificial intelligence and getting into this getting them into their academics and making them a part of it is very important, including the trainers who train them, making them future ready into what you are doing is amazing. And the speed that which is growing, it is calling for a lot of training that needs to be done. Can you from your angle throw some light on how we could make them future ready? How these people who are, who are management graduates and from schools who are coming out, how do we get into this part of technology that you spoke about? Oh, so this is, this is really a challenge because I think everyone will need to understand at some level what this technology does. And I think that we have to rethink how we get everyone into these and that this, this kind of education has to be at many different levels, right? There are from a core set of having people who are extremely good at some, and there you don't need as many, but then there are basically vast numbers of people who can actually leverage these tools. By the way, the most important thing about, I mean, maybe that's part of what makes an LLM interesting is that how you use it, your, your, your, your, your mileage varies by that. And to understand how to actually leverage this in an interesting way is something that we have to widely teach many, many people. And, and, and, and because asking the, you know, things in the right way and having the right kind of applications will make a huge difference to how people can leverage these tools. Awesome. Thank you. Thank you very much Vivek. Very good luck to Sarvam and good luck to India. I think it's going to be a lot right on your shoulders. Thanks. Thanks, Bala. Thank you, Mr. Raghavan. And